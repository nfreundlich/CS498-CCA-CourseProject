{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ftplib import FTP\n",
    "import datetime\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "AWS_BUCKET_NAME = 'cca498'\n",
    "\n",
    "def upload_to_s3(data_path=\"/tmp\", version=1):\n",
    "    bucket = s3.Bucket(AWS_BUCKET_NAME)\n",
    "    \n",
    "    # find the directories in the download dir\n",
    "    dirs = os.listdir(data_path)\n",
    "    for dir_ in dirs:\n",
    "        bucket_path = \"v\"+str(version)+\"/\"+dir_\n",
    "        try:\n",
    "            for file in os.listdir(os.path.join(data_path, dir_)):\n",
    "                bucket.put_object(\n",
    "                    ACL='public-read',\n",
    "                    ContentType='application/json',\n",
    "                    Key=bucket_path + \"/\" + file,\n",
    "                    Body=\"Foobar\",\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to locate credentials\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(data_path=\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function download_files:\n",
    "# FTPs to ftp_path, gets list of files in the directory for the current year and month (note that this may cause\n",
    "# problems on the first day of the month downloading the files from the last day of the previous month); makes a list \n",
    "# of files to be download. Then downloads the files with wget (ftp was not downloading the entire file); unzips the \n",
    "# tarballs and then deletes the tar.gz file.\n",
    "# \n",
    "# Params:\n",
    "# - data_path -> path to download data to\n",
    "# - ftp_path -> URI for FTP\n",
    "# - username, password -> username and password for FTP login\n",
    "# - year, month -> year and month to download data for, if None will use current month and year\n",
    "# - max_files -> max number of files to download, useful for debuggin\n",
    "# - delete_files -> whether to delete the files that have been successfully extracted\n",
    "#\n",
    "# Returns:\n",
    "# - list of files downloaded and successfully extracted\n",
    "#\n",
    "# Note that sometimes using the URL throws an error, in this case use the IP address: 91.250.107.123\n",
    "\n",
    "def download_files(data_path=\"/tmp\", ftp_path=\"91.250.107.123\", username=\"guest\", password=\"guest\", year=None, month=None, max_files=None, delete_files=True):\n",
    "    ## USE FTP TO GET THE LIST OF FILES TO DOWNLOAD\n",
    "    with FTP(ftp_path, user=username, passwd=password) as ftp:\n",
    "        # create the directory name for the current month and year\n",
    "        # we may want to do this for yesterday \n",
    "        now = datetime.datetime.now()\n",
    "        if year is None:\n",
    "            year = str(now.year)\n",
    "        if month is None:\n",
    "            month = datetime.datetime.now().strftime('%m')\n",
    "\n",
    "        # go to that directory and get the files in it\n",
    "        ftp.cwd('daily-packages/' + year + \"/\" + month) \n",
    "        dir_list = ftp.nlst() \n",
    "        files_to_download = []\n",
    "\n",
    "        # loop through the files\n",
    "        for file in dir_list:\n",
    "            # download the file with wget since ftplib seems to only download a small part of the file\n",
    "            file_path = \"ftp://\"+username+\":\"+password+\"@\" + ftp_path + \"/daily-packages/\" + year + \"/\" + month + \"/\" + file\n",
    "            files_to_download.append(file_path)\n",
    "    \n",
    "    # the newest file will be the last one in the sorted list\n",
    "    if max_files is not None:\n",
    "        files_to_download = sorted(files_to_download)[-max_files:]\n",
    "    \n",
    "    # download the files with wget so we can download the entire file without errors            \n",
    "    downloaded_files = []\n",
    "    for file in files_to_download:\n",
    "        try:\n",
    "            print(\"\\nDownloading\", file)\n",
    "            file_name = file.split(\"/\")[-1]\n",
    "            d_file = urllib.request.urlretrieve(file, os.path.join(data_path, file_name))[0]\n",
    "            downloaded_files.append(d_file)\n",
    "        except Exception as e:\n",
    "            print(\"Error downloading\", file, e)\n",
    "    \n",
    "    extracted_files = []\n",
    "    # extract the tarballs\n",
    "    for file in downloaded_files:\n",
    "        print(\"\\nExtracting:\", file)\n",
    "        try:\n",
    "            if (file.endswith(\"tar.gz\")):\n",
    "                tar = tarfile.open(file, \"r:gz\")\n",
    "                tar.extractall(data_path)\n",
    "                tar.close()\n",
    "            elif (file.endswith(\"tar\")):\n",
    "                tar = tarfile.open(file, \"r:\")\n",
    "                tar.extractall()\n",
    "                tar.close()\n",
    "            \n",
    "            extracted_files.append(file)\n",
    "            if delete_files:\n",
    "                # if everything was properly extracted we can delete the file\n",
    "                os.remove(file)\n",
    "        except:\n",
    "            print(\"Error extracting\", file)\n",
    "\n",
    "    return extracted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ftp://guest:guest@91.250.107.123/daily-packages/2019/02/20190227_2019041.tar.gz\n",
      "\n",
      "Extracting: tmp\\20190227_2019041.tar.gz\n"
     ]
    }
   ],
   "source": [
    "df = download_files(max_files=1, data_path=\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmp\\\\20190227_2019041.tar.gz']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
