{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(event):\n",
    "    s3 = boto3.resource('s3')\n",
    "    objects = event['key1']['Records']\n",
    "    \n",
    "    downloaded_files = []\n",
    "    \n",
    "    for object_ in objects:\n",
    "        key = object_['s3']['object']['key']\n",
    "        bucket = object_['s3']['bucket']['name']\n",
    "    \n",
    "        file_name = bucket.split(\"/\")[-1]\n",
    "    \n",
    "        s3.Bucket(bucket).download_file(key, os.path.join(\"/tmp\", file_name))\n",
    "        \n",
    "        downloaded_files.append(os.path.join(\"/tmp\", file_name))\n",
    "        \n",
    "    return downloaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files(files, delete_files=True, data_path=\"/tmp\"):\n",
    "    extracted_files = []\n",
    "    \n",
    "    for file in files:\n",
    "        print(\"\\nExtracting:\", file)\n",
    "        try:\n",
    "            if (file.endswith(\"tar.gz\")):\n",
    "                tar = tarfile.open(file, \"r:gz\")\n",
    "                tar.extractall(data_path)\n",
    "                tar.close()\n",
    "            elif (file.endswith(\"tar\")):\n",
    "                tar = tarfile.open(file, \"r:\")\n",
    "                tar.extractall()\n",
    "                tar.close()\n",
    "            \n",
    "            extracted_files.append(file)\n",
    "            if delete_files:\n",
    "                # if everything was properly extracted we can delete the file\n",
    "                os.remove(file)\n",
    "        except:\n",
    "            print(\"Error extracting\", file)\n",
    "            \n",
    "    return extracted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all currencies to EUR\n",
    "def convert_currencies(values, currencies):\n",
    "    url = \"https://api.exchangeratesapi.io/latest\"\n",
    "    content = urllib.request.urlopen(url).read()\n",
    "    exchange_rates = json.loads(content.decode())\n",
    "    results = []\n",
    "    \n",
    "    for value, currency in zip(values, currencies):\n",
    "        if currency == \"EUR\":\n",
    "            results.append(value)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                exchange_rate = exchange_rates['rates'][currency]\n",
    "                converted_value = float(value) / exchange_rate\n",
    "                results.append(converted_value)\n",
    "            # if we don't have a rate for the currency use NaN\n",
    "            except:\n",
    "                results.append(np.nan)\n",
    "                \n",
    "    return results\n",
    "\n",
    "def unwind_descriptions(short_desc):\n",
    "    # get the text from the OrderedDicts in the short descriptions\n",
    "    for i, foo in enumerate(short_desc):\n",
    "        if type(foo) != str:\n",
    "            if type(foo) == list:\n",
    "                for j, bar in enumerate(foo):\n",
    "                    if type(bar) == collections.OrderedDict:\n",
    "                        bar = bar['#text']\n",
    "                        short_desc[i][j] = bar\n",
    "            elif type(foo) == collections.OrderedDict:\n",
    "                foo = foo['#text']\n",
    "                short_desc[i] = foo\n",
    "\n",
    "    # flatten the lists\n",
    "    for i, foo in enumerate(short_desc):\n",
    "        if type(foo) == list:\n",
    "            foo = \" \".join(foo)\n",
    "            short_desc[i] = foo\n",
    "            \n",
    "    return short_desc\n",
    "\n",
    "# function to recursively extract data from XML files\n",
    "def extract_xml(xml_dict, parent_key=\"\", results_dict={}):\n",
    "    # make sure the input is a an ordered dictionary\n",
    "    if isinstance(xml_dict, collections.OrderedDict):\n",
    "        for key1, value1 in xml_dict.items():\n",
    "            # remove unneeded characters from the key\n",
    "            if key1[0] == \"@\" or key1[0] == \"#\":\n",
    "                key1 = key1[1:]\n",
    "            \n",
    "            # FT means FT, we can ignore these\n",
    "            if key1 == \"FT\":\n",
    "                continue\n",
    "            \n",
    "            # add the parent key for clarity\n",
    "            if len(parent_key):\n",
    "                # if the current key is text we will not append it to the parent\n",
    "                if key1 != \"text\":\n",
    "                    new_key = parent_key + \"__\" + key1\n",
    "                else:\n",
    "                    new_key = parent_key\n",
    "            else:\n",
    "                new_key = key1\n",
    "            \n",
    "            # if the value is a string directly add it\n",
    "            if isinstance(value1, str):\n",
    "                # if the key is \"P\" the value is a new paragraph and should be appended\n",
    "                # not overwritten, if the key is \"FT\" it is a font thing and should also be appended\n",
    "                if key1 != \"P\" and key1 != \"FT\":\n",
    "                    # if the key does NOT exist add it\n",
    "                    if new_key not in results_dict:\n",
    "                        results_dict[new_key] = value1\n",
    "                    # else instead of overwriting the data let's make a list of the values\n",
    "                    else:\n",
    "                        if isinstance(results_dict[new_key], list):\n",
    "                            results_dict[new_key].append(value1)\n",
    "                        elif isinstance(results_dict[new_key], str):\n",
    "                            results_dict[new_key] = [results_dict[new_key]]\n",
    "                            results_dict[new_key].append(value1)\n",
    "                else:\n",
    "                    if parent_key in results_dict:\n",
    "                        if isinstance(results_dict[parent_key], list):\n",
    "                            results_dict[parent_key].append(value1)\n",
    "                        elif isinstance(results_dict[parent_key], str):\n",
    "                            listed_vals = [results_dict[parent_key], value1]\n",
    "                            results_dict[parent_key] = listed_vals\n",
    "                    else:\n",
    "                        results_dict[parent_key] = value1\n",
    "            \n",
    "            # else if it is a list loop through and add the items\n",
    "            # note that this will overwrite the previous entries\n",
    "            elif isinstance(value1, list):\n",
    "                item_string = []\n",
    "                for item in value1:\n",
    "                    if isinstance(item, collections.OrderedDict):\n",
    "                        results_dict = extract_xml(item, new_key, results_dict)\n",
    "                    elif isinstance(item, str):\n",
    "                        item_string.append(item)\n",
    "                if len(item_string) > 0:\n",
    "                    if key1 != \"P\":\n",
    "                        results_dict[new_key] = item_string\n",
    "                    else:\n",
    "                        results_dict[parent_key] = item_string\n",
    "                        \n",
    "            # else if the value is an OrderedDict recurse\n",
    "            elif isinstance(value1, collections.OrderedDict):\n",
    "                # handle Ps differently, they are paragraphs and do not need to be recursed into\n",
    "                if key1 != \"P\":\n",
    "                    results_dict = extract_xml(value1, new_key, results_dict)\n",
    "                else:\n",
    "                    # if the key is P and is has text use the text, otherwise recurse as usual\n",
    "                    try:\n",
    "                        results_dict[parent_key] = value1['#text']\n",
    "                    except:\n",
    "                        results_dict = extract_xml(value1, new_key, results_dict)\n",
    "                    \n",
    "    elif isinstance(xml_dict, str):\n",
    "        results_dict[parent_key] = xml_dict\n",
    "    \n",
    "    elif isinstance(xml_dict, list):\n",
    "        pass\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/tmp\"\n",
    "\n",
    "## Function load_data - \n",
    "## Params -\n",
    "## - data_dir - directory to extract from\n",
    "## - language - languages to extract from the XML\n",
    "## - doc_type_filter - if specified function will only return XML documents of the specified type\n",
    "## Returns - \n",
    "## - dataframe of parsed documents\n",
    "def load_data(data_dir, language=\"EN\", doc_type_filter=None):\n",
    "    parsed_xmls = []\n",
    "    \n",
    "    language_tenders = []\n",
    "    all_tenders = []\n",
    "    \n",
    "        \n",
    "    # loop through the files\n",
    "    for dir_ in os.listdir(data_dir):\n",
    "        files = os.listdir(os.path.join(data_path, dir_))\n",
    "        date = dir_.split(\"_\")[0]\n",
    "        for file in files:\n",
    "            # read the contents of the file\n",
    "            with io.open(os.path.join(data_path, dir_, file), 'r', encoding=\"utf-8\") as f:\n",
    "                xml = f.read()\n",
    "                parsed_xml = xmltodict.parse(xml)\n",
    "                \n",
    "                if doc_type_filter is not None and parsed_xml['TED_EXPORT']['CODED_DATA_SECTION']['CODIF_DATA']['TD_DOCUMENT_TYPE']['#text'] != doc_type_filter:\n",
    "                    continue\n",
    "                    \n",
    "                parsed_xmls.append(parsed_xml)\n",
    "                \n",
    "                # get some header info\n",
    "                forms_section = parsed_xml['TED_EXPORT']['FORM_SECTION']\n",
    "                notice_data = parsed_xml['TED_EXPORT']['CODED_DATA_SECTION']['NOTICE_DATA']\n",
    "                \n",
    "                header_info = {}\n",
    "                header_info['DATE'] = date\n",
    "                header_info['FILE'] = file\n",
    "                # extract the info from the codified data section\n",
    "                header_info = extract_xml(parsed_xml['TED_EXPORT']['CODED_DATA_SECTION']['CODIF_DATA'], \"\", header_info)\n",
    "                \n",
    "                # extract the info from the notice_data section, except we don't need the URI_LIST\n",
    "                notice_data.pop(\"URI_LIST\")\n",
    "                header_info = extract_xml(notice_data, \"\", header_info)\n",
    "                \n",
    "                if isinstance(notice_data['ORIGINAL_CPV'], list):\n",
    "                    header_info['ORIGINAL_CPV_CODE'] = []\n",
    "                    header_info['ORIGINAL_CPV_TEXT'] = []\n",
    "                    for cpv_info in notice_data['ORIGINAL_CPV']:\n",
    "                        header_info['ORIGINAL_CPV_CODE'].append(cpv_info['@CODE'])\n",
    "                        header_info['ORIGINAL_CPV_TEXT'].append(cpv_info['#text'])\n",
    "                else:\n",
    "                    header_info['ORIGINAL_CPV_CODE'] = notice_data['ORIGINAL_CPV']['@CODE']\n",
    "                    header_info['ORIGINAL_CPV_TEXT'] = notice_data['ORIGINAL_CPV']['#text']\n",
    "\n",
    "                try:\n",
    "                    header_info['REF_NO'] = notice_data['REF_NOTICE']['NO_DOC_OJS']\n",
    "                except:\n",
    "                    header_info['REF_NO'] = \"\"\n",
    "                    \n",
    "                forms = forms_section.keys()\n",
    "                \n",
    "                for form in forms:\n",
    "                    try:\n",
    "                        form_contents = forms_section[form]\n",
    "                            \n",
    "                        if isinstance(form_contents, list):\n",
    "                            for i, form_content in enumerate(form_contents):\n",
    "                                all_tenders.append((header_info, form_content))\n",
    "                                if language is not None and form_content['@LG'] == language:\n",
    "                                    language_tenders.append((header_info, form_content))\n",
    "                        elif isinstance(form_contents, collections.OrderedDict):\n",
    "                            all_tenders.append((header_info, form_contents))\n",
    "                            if language is not None and form_contents['@LG'] == language:\n",
    "                                language_tenders.append((header_info, form_contents))\n",
    "                    except Exception as e:\n",
    "                        print(\"File 1\", file, e)\n",
    "\n",
    "    if language == None:\n",
    "        language_tenders = all_tenders\n",
    "    \n",
    "    parsed_data = []\n",
    "    \n",
    "    for (header, tender) in language_tenders:\n",
    "        flattened = {}\n",
    "        \n",
    "        # add some fields\n",
    "        for key in header.keys():\n",
    "            flattened[key] = header[key]\n",
    "        \n",
    "        flattened = extract_xml(tender, \"\", flattened)\n",
    "        \n",
    "        parsed_data.append(flattened)\n",
    "\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "        \n",
    "    # try convert Currencies to Euros, some doc types don't have this so it's not a big deal if there's an error\n",
    "    try:\n",
    "        df['VALUE_EUR'] = convert_currencies(df['VALUES_VALUE'].values, df['VALUES_VALUE_CURRENCY'].values)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return_df = pd.DataFrame(columns=USE_COLS)\n",
    "    for col in df.columns:\n",
    "        if col in USE_COLS:\n",
    "            return_df[col] = df[col]\n",
    "\n",
    "    return return_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
